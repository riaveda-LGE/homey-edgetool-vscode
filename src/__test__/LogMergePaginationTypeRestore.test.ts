// src/__test__/LogMergePaginationTypeRestore.test.ts

import type { LogEntry } from '@ipc/messages';
import * as fs from 'fs';
import * as fsp from 'fs/promises';
import * as path from 'path';

import { ChunkWriter } from '../core/logs/ChunkWriter.js';
import { mergeDirectory } from '../core/logs/LogFileIntegration.js';
import { ManifestWriter } from '../core/logs/ManifestWriter.js';
import { PagedReader } from '../core/logs/PagedReader.js';
import { paginationService } from '../core/logs/PaginationService.js';
import type { ParserConfig } from '../core/logs/ParserEngine.js';
import {
  compileParserConfig,
  extractByCompiledRule,
  matchRuleForPath,
  shouldUseParserForFile,
} from '../core/logs/ParserEngine.js';
import { MERGED_CHUNK_MAX_LINES } from '../shared/const.js';
// ğŸ” í…ŒìŠ¤íŠ¸ FS í—¬í¼: ê³ ì • out ë£¨íŠ¸ í•˜ìœ„ì— ìœ ë‹ˆí¬ ë””ë ‰í„°ë¦¬ ìƒì„±/ì‚­ì œ
import { cleanDir, prepareUniqueOutDir } from './helpers/testFs.js';

jest.setTimeout(120_000);

// â”€â”€ ê²½ë¡œ ìƒìˆ˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const REPO_ROOT = path.resolve(__dirname, '..', '..');
const TEST_LOG_DIR = path.join(REPO_ROOT, '.test_log');
const PARSER_TEMPLATE_PATH = path.join(
  REPO_ROOT,
  'media',
  'resources',
  'custom_log_parser.template.v1.json',
);

// â”€â”€ ìœ í‹¸(ë¹„êµ ì•ˆì •í™”) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// eslint-disable-next-line no-control-regex
const ANSI_RE = /[\u001B\u009B][[\]()#;?]*(?:\d{1,4}(?:;\d{0,4})*)?[0-9A-PR-TZcf-ntqry=><~]/g;
function stripAnsi(s: string) {
  return s.replace(ANSI_RE, '');
}
function normalizeForCompare(line: string): string {
  return stripAnsi(line)
    .replace(/[ \t]+/g, ' ')
    .trim();
}
function normalizeNewlines(s: string) {
  return s.replace(/\r\n/g, '\n');
}

// BOM ë¬´ì‹œ: ì›ë³¸ vs ì¬êµ¬ì„± ë¹„êµ ì‹œ U+FEFF ì¡´ì¬ ì—¬ë¶€ëŠ” ì˜ë¯¸ ì—†ìœ¼ë¯€ë¡œ ì œê±°
function stripBomAll(s: string) {
  return s.replace(/\uFEFF/g, '');
}

// âœ… í…ŒìŠ¤íŠ¸ì—ì„œë§Œ ì‚¬ìš©í•  "í”„ë¡œì„¸ìŠ¤ëª… â†’ ë³µì› ëŒ€ìƒ íŒŒì¼ëª…" ë§¤í•‘
//   - ì´ ëª©ë¡ì— í¬í•¨ëœ ê²ƒë“¤ë§Œ ë³µì› ë° ì›ë³¸ ëŒ€ì¡°ë¥¼ ìˆ˜í–‰í•œë‹¤.
const PROC_TO_FILE: Record<string, string> = {
  'homey-matter': 'matter.log',
  'homey-z3gateway': 'z3gateway.log',
  kernel: 'kernel.log',
  'homey-pro': 'homey-pro.log',
  cpcd: 'cpcd.log',
};
const FILE_BASES_OF_INTEREST = new Set(
  Object.values(PROC_TO_FILE).map((n) => n.replace(/\.log$/i, '')),
);

/** íŒŒì¼ëª… ì •ê·œí™”: PID ë“± ëŒ€ê´„í˜¸ íƒœê·¸ ì œê±°, ê³µë°±/ëŒ€ì†Œë¬¸ì/êµ¬ë¶„ì í†µì¼ */
function canonicalizeProcName(name: string) {
  return name
    .replace(/\[[^\]]*\]/g, '') // [1863], [4413] ë“± ì œê±°
    .replace(/\s+/g, '') // ê³µë°± ì œê±°
    .replace(/[_]+/g, '-') // _ â†’ - í†µì¼(ì„ íƒ)
    .toLowerCase();
}

/** REBUILT_DIR ë‚´ì—ì„œ procì— í•´ë‹¹í•˜ëŠ” ë³µì›ë³¸ ë¡œê·¸ ì‹¤ì œ ê²½ë¡œë¥¼ íƒìƒ‰ */
function resolveRebuiltPath(proc: string, rebuiltDir: string) {
  const direct = path.join(rebuiltDir, `${proc}.log`);
  if (fs.existsSync(direct)) return direct;
  try {
    const files = fs.readdirSync(rebuiltDir).filter((f) => f.toLowerCase().endsWith('.log'));
    const target = canonicalizeProcName(proc);
    const hit = files.find((f) => canonicalizeProcName(path.basename(f, '.log')) === target);
    if (hit) return path.join(rebuiltDir, hit);
    // prefix ë§¤ì¹˜ë„ í•œ ë²ˆ ë” ì‹œë„ (ì˜ˆ: homey-matter vs homey-matter-xyz)
    const prefix = files.find((f) =>
      canonicalizeProcName(path.basename(f, '.log')).startsWith(target),
    );
    if (prefix) return path.join(rebuiltDir, prefix);
    // ëª» ì°¾ìœ¼ë©´ ë””ë²„ê¹… í¸ì˜ë¡œ ëª©ë¡ ë¡œê·¸ ì¶œë ¥
    // (jest ì‹¤í–‰ ì‹œ ì½˜ì†”ì— ê²½ê³ ë¡œ ë‚¨ê¹€)

    console.warn(`[resolveRebuiltPath] Not found for "${proc}". Candidates: ${files.join(', ')}`);
  } catch {}
  return direct;
}

/** e.text ë˜ëŠ” parsedì—ì„œ processëª… ì¶”ì¶œ */
function extractProcess(e: LogEntry): string | undefined {
  const p = (e as any)?.parsed?.process;
  if (p && String(p).trim()) return String(p).trim();
  const t = String(e.text || '');
  // â€˜[â€™ì€ ë¬¸ì í´ë˜ìŠ¤ ë‚´ë¶€ì—ì„œ ì´ìŠ¤ì¼€ì´í”„ê°€ ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ì œê±°
  const m = t.match(/^\[[^\]]+\]\s+([^\s:[]+)(?:\[\d+\])?:/);
  return m ? m[1] : undefined;
}

/** .test_log ë°‘ì˜ ê¸°ì¤€ ì›ë³¸(log íšŒì „ë³¸ ì œì™¸, *.log ë§Œ) */
function listOriginalLogFiles(dir: string): Map<string, string> {
  const out = new Map<string, string>();
  const names = fs.readdirSync(dir);
  for (const n of names) {
    if (!/\.log$/i.test(n)) continue; // *.log ë§Œ
    if (/\.log\.\d+$/i.test(n)) continue; // íšŒì „ë³¸ ì œì™¸
    out.set(n.replace(/\.log$/i, ''), path.join(dir, n));
  }
  return out;
}

/** ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ë°˜í™˜ë˜ì—ˆëŠ”ì§€ ê°„ë‹¨ ê²€ì¦ */
function expectAscByTs(rows: LogEntry[]) {
  for (let i = 1; i < rows.length; i++) {
    expect(rows[i].ts).toBeGreaterThanOrEqual(rows[i - 1].ts);
  }
}

// â”€â”€ í…ŒìŠ¤íŠ¸ ë³¸ë¬¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
describe('íŒŒì¼ ë³‘í•© â†’ Pagination ì˜¤ë¦„ì°¨ìˆœ â†’ íƒ€ì…ë³„ ë³µì› â†’ ì›ë³¸ ëŒ€ì¡°', () => {
  it('config ê¸°ë°˜ ì‹¤ì œ ë³‘í•© ê²°ê³¼ë¡œ roundtrip ë³µì› ê²€ì¦', async () => {
    // ì‚¬ì „ ì¡°ê±´
    if (!fs.existsSync(TEST_LOG_DIR)) {
      throw new Error(`Missing test logs: ${TEST_LOG_DIR}`);
    }
    const parserConfig: ParserConfig = JSON.parse(fs.readFileSync(PARSER_TEMPLATE_PATH, 'utf8'));
    const compiled = compileParserConfig(parserConfig)!;

    // 0) í…ŒìŠ¤íŠ¸ ì „ìš© ì‘ì—… ë””ë ‰í„°ë¦¬ (helpers/testFs ì‚¬ìš©)
    const workDir = prepareUniqueOutDir('merge-pagination-restore');

    try {
      // 1) ì‹¤ì œ í”„ë¡œì íŠ¸ ë¡œì§ë§Œìœ¼ë¡œ ë³‘í•© ì‹¤í–‰
      //    - mergeDirectoryì˜ onBatch ìŠ¤íŠ¸ë¦¼ì„ ChunkWriter+ManifestWriterë¡œ ë°›ì•„ì„œ NDJSON ì²­í¬/manifest ì €ì¥
      const MANIFEST_DIR = path.join(workDir, 'manifest');
      await fsp.mkdir(MANIFEST_DIR, { recursive: true });
      const chunkWriter = new ChunkWriter(MANIFEST_DIR, MERGED_CHUNK_MAX_LINES);
      const manifest = await ManifestWriter.loadOrCreate(MANIFEST_DIR);

      // ğŸ“Œ ì¤‘ê°„ ì‚°ì¶œë¬¼(íƒ€ì…ë³„ jsonl ë“±)ì„ src/__test__/out/... í•˜ìœ„ë¡œ ê°•ì œ
      const INTERMEDIATE_DIR = path.join(workDir, 't1_merged');
      const RAW_DIR = path.join(workDir, 't1_raw'); // í•„ìš” ì—†ìœ¼ë©´ ì‚¬ìš© ì•ˆ í•´ë„ ë¨
      await fsp.mkdir(INTERMEDIATE_DIR, { recursive: true }).catch(() => {});
      await fsp.mkdir(RAW_DIR, { recursive: true }).catch(() => {});

      let merged = 0;

      // íƒ€ì… ì„ ì–¸ê³¼ì˜ ì¶©ëŒì„ í”¼í•˜ê¸° ìœ„í•´ ì˜µì…˜ ê°ì²´ì— í•œ ë²ˆ any ìºìŠ¤íŒ…
      const mergeOpts: any = {
        dir: TEST_LOG_DIR,
        parser: parserConfig,
        preserveFullText: true, // í—¤ë” ë³µì›(ì›ë¬¸ í¬ë§· í™•ë³´)
        batchSize: 200,
        // âœ… ê¸°ë³¸ê°’(.test_log/merged)ì„ ì‚¬ìš©í•˜ì§€ ì•Šê³  out í•˜ìœ„ë¡œ ë³´ëƒ„
        mergedDirPath: INTERMEDIATE_DIR,
        rawDirPath: RAW_DIR,
        onBatch: async (logs: LogEntry[]) => {
          const made = await chunkWriter.appendBatch(logs);
          for (const c of made) {
            manifest.addChunk(c.file, c.lines, merged);
            merged += c.lines;
          }
        },
      };

      await mergeDirectory(mergeOpts);

      const rem = await chunkWriter.flushRemainder();
      if (rem) {
        manifest.addChunk(rem.file, rem.lines, merged);
        merged += rem.lines;
      }
      manifest.setTotal(merged);
      await manifest.save();
      expect(merged).toBeGreaterThan(0);

      // 2) PaginationServiceë¡œ â€œì˜¤ë¦„ì°¨ìˆœâ€ ë°˜í™˜ í™•ì¸
      await paginationService.setManifestDir(MANIFEST_DIR);
      await paginationService.reload(); // íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ì „í™˜
      const total = paginationService.getFileTotal() ?? 0;
      expect(total).toBe(merged);

      const first = await paginationService.readRangeByIdx(1, Math.min(50, total));
      expectAscByTs(first);

      if (total > 200) {
        const mid = Math.floor(total / 2);
        const midRows = await paginationService.readRangeByIdx(mid - 25, mid + 25);
        expectAscByTs(midRows);
      }

      const tailRows = await paginationService.readRangeByIdx(Math.max(1, total - 49), total);
      expectAscByTs(tailRows);

      // 3) (í…ŒìŠ¤íŠ¸ êµ¬í˜„) ìµœì¢… ë³‘í•©ëœ ë¡œê·¸ë¥¼ â€œë§¨ ì•„ë˜ì¤„ë¶€í„° ìœ„ë¡œâ€ ì½ì–´ íƒ€ì…ë³„ íŒŒì¼ë¡œ ë³µì›
      const reader = await PagedReader.open(MANIFEST_DIR);
      const totalLines = reader.getTotalLines() ?? 0;
      const allDesc = await reader.readLineRange(0, totalLines, {
        skipInvalid: true,
      });

      // .test_log ë‚´ ì›ë³¸ ì¤‘, ë§¤í•‘ ëŒ€ìƒì— í•´ë‹¹í•˜ëŠ” íŒŒì¼ë§Œ ê³ ë¥¸ë‹¤.
      const originalsAll = listOriginalLogFiles(TEST_LOG_DIR); // Map<fileBase, filePath>
      const originals = new Map(
        [...originalsAll].filter(([base]) => FILE_BASES_OF_INTEREST.has(base)),
      );
      expect(originals.size).toBeGreaterThan(0);

      const REBUILT_DIR = path.join(workDir, 'rebuilt_by_process');
      await fsp.mkdir(REBUILT_DIR, { recursive: true });

      // í”„ë¡œì„¸ìŠ¤ëª… â†’ ì‹¤ì œ ì“°ê¸° ëŒ€ìƒ íŒŒì¼ ê²½ë¡œ ë§¤í•‘ êµ¬ì„±
      const targetsByProc = new Map<string, string>();
      for (const [procName, fileName] of Object.entries(PROC_TO_FILE)) {
        const base = fileName.replace(/\.log$/i, '');
        if (originals.has(base)) {
          targetsByProc.set(procName, path.join(REBUILT_DIR, fileName));
        }
      }
      const targetProcs = new Set(targetsByProc.keys());

      // ë§¨ ì•„ë˜ì¤„(ê°€ì¥ ì˜¤ë˜ëœ)ë¶€í„° ìœ„ë¡œ â†’ ë§¤í•‘ëœ íŒŒì¼ì—ë§Œ append
      for (let i = allDesc.length - 1; i >= 0; i--) {
        const e = allDesc[i] as LogEntry;
        const proc = extractProcess(e);
        if (!proc || !targetProcs.has(proc)) continue;
        const outPath = targetsByProc.get(proc)!;
        await fsp.appendFile(outPath, String(e.text ?? '') + '\n', 'utf8');
      }

      // 4) ë³µì›ë³¸ vs ì›ë³¸ ë¼ì¸-ë°”ì´-ë¼ì¸ ë¹„êµ
      for (const [fileBase, origPath] of originals) {
        const rebuiltPath = resolveRebuiltPath(fileBase, REBUILT_DIR);
        const original = stripBomAll(normalizeNewlines(fs.readFileSync(origPath, 'utf8')));
        let rebuilt = '';
        if (fs.existsSync(rebuiltPath)) {
          rebuilt = stripBomAll(normalizeNewlines(fs.readFileSync(rebuiltPath, 'utf8')));
        } else {
          console.warn(
            `[compare] rebuilt log not found for "${fileBase}" â†’ expected at: ${rebuiltPath}`,
          );
        }

        const origLines = original.split('\n');
        const rebLines = rebuilt.split('\n');
        if (origLines.length && origLines[origLines.length - 1] === '') origLines.pop();
        if (rebLines.length && rebLines[rebLines.length - 1] === '') rebLines.pop();

        // === ì‹¤ì œ íŒŒì´í”„ë¼ì¸ì˜ "ë“œë ê·œì¹™"ì„ ê¸°ëŒ€ê°’ì— ë°˜ì˜ ===
        // 1) ì´ íŒŒì¼ì— íŒŒì„œê°€ ì ìš©ë˜ëŠ”ì§€ í”„ë¦¬í”Œë¼ì´íŠ¸ë¡œ í™•ì¸
        const baseName = path.basename(origPath).replace(/\\/g, '/');
        const useParser = await shouldUseParserForFile(origPath, baseName, compiled);
        const rule = matchRuleForPath(baseName, compiled);

        // 2) ë¹„êµ ëŒ€ìƒì—ì„œ ì œì™¸í•´ì•¼ í•  ë¼ì¸ í•„í„°ë§
        //   - ë¹ˆ ì¤„("") â†’ ë¦¬ë” ë‹¨ê³„ì—ì„œ ë“œë
        //   - (íŒŒì„œ ì ìš© íŒŒì¼ && time/process/pid ì…‹ ëª¨ë‘ ì—†ìŒ) â†’ íŒŒì„œ ê²Œì´íŠ¸ì—ì„œ ë“œë
        const origLinesAfterDrop = origLines.filter((line) => {
          if (line === '') return false; // ë¹ˆ ì¤„ì€ í•­ìƒ ì œì™¸
          if (!useParser || !rule) return true;
          const f = extractByCompiledRule(line, rule);
          const hasTime = !!(f.time && String(f.time).trim());
          const hasProc = !!(f.process && String(f.process).trim());
          const pidRaw = f.pid;
          const hasPid = !(pidRaw === undefined || pidRaw === null || String(pidRaw).trim() === '');
          return hasTime || hasProc || hasPid;
        });

        // ANSI ë° ê³µë°± ì°¨ì´ëŠ” ë¬´ì‹œ(í”„ë¡œì íŠ¸ ë¡œì§ì´ ANSIë¥¼ ì •ê·œí™”í•  ìˆ˜ ìˆìŒ)
        const normOrig = origLinesAfterDrop.map(normalizeForCompare);
        const normReb = rebLines.map(normalizeForCompare);

        expect(normReb).toEqual(normOrig);
      }
    } finally {
      // ğŸ”š í…ŒìŠ¤íŠ¸ ì‚°ì¶œë¬¼ ì •ë¦¬ (ë””ë²„ê¹…ì„ ìœ„í•´ ê¸°ë³¸ì€ ë³´ì¡´)
      try {
        if (workDir && fs.existsSync(workDir)) cleanDir(workDir);
      } catch {}
    }
  });
});
